---
  title: "TS project_3"
author: "Vamshi Gadepally"
date: "2023-05-06"
output: html_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Import Libraries}
library(fpp)
library(TSA)
library(tseries)
library(ggplot2)
library(forecast)
library(caret)
library(lubridate)
library(dplyr)
library(AICcmodavg)
```

```{r Q1}
data <- read.csv("Metro_Interstate_Traffic_Volume.csv")
```

```{r Q18}
# Missing temp values (zero degree Kelvin entries)
missing_temp_indices <- which(data$temp==0)
missing_temp_indices
```

```{r Q19}
# Replacing the missing temp values (zero degree Kelvin entries) with the previous recorded temp value
# values before imputation
data$temp[11898:11905]
data$temp[11946:11955]

# substitute the values of the missing temperature with the temperature of the previous hour
for (i in missing_temp_indices) {
  data[i, "temp"] <- data[i - 1, "temp"]}

# values after imputation
data$temp[11898:11905]
data$temp[11946:11955]
```

```{r Q2}
# Transform temp column from Kelvin to Fahrenheit
data$temp_f <- (data$temp - 273.15) * 1.8 + 32
```

```{r Q3}
# Create new column with day of the week (in numeric form)
data$day_of_week <- wday(ymd_hms(data$date_time)) #Sunday is 1
```

```{r Q4}
# Create binary column for holiday
data$holiday_binary <- ifelse(data$holiday != "None", 1, 0)
# Create binary column for rain_1h
data$rain_1h_binary = ifelse(data$rain_1h > 0, 1, 0)
# Create binary column for snow_1h
data$snow_1h_binary = ifelse(data$snow_1h > 0, 1, 0)
```

```{r Q20}
# Check for missing values
missing_values <- sapply(data, function(x) sum(is.na(x)))
missing_values_data <- data.frame(Variable = names(data), Missing_Values = missing_values)
missing_values_data # No missing values
```

```{r Q6}
# Creating a copy for EDA
data_2<-data.frame(data)
```

```{r Q6}
# Convert the 'date_time' column to a date format
data_2$date <- as.Date(data_2$date_time)

# Extract month and year information
data_2$month <- format(data_2$date, "%m")
data_2$year <- format(data_2$date, "%Y")

# Create a function to count the number of '1' observations in each Categorical variable
count_ones <- function(variable) {
  table(data_2$year, data_2$month, data_2[[variable]] == 1)
}
```

```{r Q6}
# Apply the function to each binary variable
rain_count <- count_ones("rain_1h_binary")
snow_count <- count_ones("snow_1h_binary")
holiday_count <- count_ones("holiday_binary")

# Display the results
print("Rain:")
print(rain_count)
print("Snow:")         # Snow has sparse data. Observations of snow ('1') in Dec 2015 and Jan 2016 only
print(snow_count)
print("Holiday:")
print(holiday_count)
```

```{r Q21}
ggplot(data_2, aes(x = temp_f)) +
  geom_histogram(bins = 30, fill = "blue", color = "white") +
  xlab("Temperature (Fahrenheit)") +
  ylab("Frequency") +
  ggtitle("Distribution of Temperature")

ggplot(data_2, aes(x = rain_1h_binary)) +
  geom_bar(fill = "green", color = "white") +
  xlab("Rainfall (Binary)") +
  ylab("Frequency") +
  ggtitle("Distribution of Rainfall (Binary)")

ggplot(data_2, aes(x = snow_1h_binary)) +
  geom_bar(fill = "orange", color = "white") +
  xlab("Snowfall (Binary)") +
  ylab("Frequency") +
  ggtitle("Distribution of Snowfall (Binary)")

ggplot(data_2, aes(x = holiday_binary)) +
  geom_bar(fill = "purple", color = "white") +
  xlab("Public Holiday (Binary)") +
  ylab("Frequency") +
  ggtitle("Distribution of Public Holiday (Binary)")

ggplot(data_2, aes(x = day_of_week)) +
  geom_bar(fill = "red", color = "white") +
  xlab("Day of Week") +
  ylab("Frequency") +
  ggtitle("Distribution of Day of Week") 
```

```{r Q5}
#Delete unused columns
df <- subset(data, select = -c(holiday, temp, clouds_all, weather_main, weather_description, snow_1h, rain_1h, snow_1h_binary))
```

```{r Q6}
#View data
View(df) 
```

```{r Q7}
tsdisplay(df$traffic_volume)
tsdisplay(df$temp_f)
```

```{r Q16}
# Splitting the data into training and testing sets
# The original data is hourly data for over 7 years, this is too much data and will lead to incorrect forecasts. Therefore we will look at only 6 months of 
# data.
# Note: this it the data that wasn't detrended / deseasonalized or transformed

# Train/Test Split
df$date_time <- as.POSIXct(df$date_time, format = "%Y-%m-%d %H:%M:%S")

# Create the train dataframe (May to August 2018)
train_start <- as.Date("2018-05-01")
train_end <- as.Date("2018-08-31")
train_df <- subset(df, date_time >= train_start & date_time <= train_end)

# Create the test dataframe (September 2018)
test_start <- as.Date("2018-09-01")
test_end <- as.Date("2018-09-30")
test_df <- subset(df, date_time >= test_start & date_time <= test_end)
```

```{r Q17}
# Selecting the target variable for univariate analysis with ARIMA models
train_df <- train_df %>% select(date_time, traffic_volume)
test_df <- test_df %>% select(date_time, traffic_volume)
```

```{r Q17}
# converting split data sets to time series objects
train_ts <- ts(train_df[, -1], frequency = 24)
test_ts <- ts(test_df[, -1], frequency = 24)
```

```{r Q9}
# Augmented Dickey-Fuller Test
adf.test(train_ts) # Appears to be stationary
```

The p-value (<0.01) is less than the significance level (0.05) for traffic_volume.
Which means that the null hypothesis can be rejected, and the time series is considered stationary.

```{r Q10}
# KPSS test
kpss.test(train_ts, null = c("Level", "Trend"), lshort = TRUE) # Appears to be stationary
```

The p-value is 0.1.
Since this value is not less than .05, we fail to reject the null hypothesis of the KPSS test.
This means we can assume that the time series is stationary.

```{r Q11}
# plotting the time series data
tsdisplay(train_ts, main = 'Metro Traffic Volume (training set) May 2018 - Aug 2018', xlab = 'Time') 
# there is clear seasonality present in the traffic_volume data
```

```{r Q12}
# Using the BoxCox.Lambda() function to check if the Box-Cox (BC) transformation is needed
lambda_value <- BoxCox.lambda(train_ts)
lambda_value #𝝀= 0.7253832 Box-Cox Transformation is required
```

```{r Q13}
# Plotting the Box-Cox Transformed time series with the best lambda
train_ts_trans <- BoxCox(train_ts, lambda_value)
tsdisplay(train_ts_trans, main = 'Box-Cox Transformation Metro Traffic Volume with 𝝀= 0.7253832', xlab = 'Time') 
```

The BoxCox.lambda() function proposed an appropriate lambda value for the data.
This means the original data did require a Box Cox transformation, suggesting the original data did 
have certain changes (increase or decrease) in variation with the level of the time series. 

```{r Q14}
# 1st Differencing (𝒅 = 𝟏)
tsdisplay(diff(train_ts_trans, lag = 24), main = '1st Differencing of Metro Traffic Volume', xlab = 'Time') 
# 1st order Differencing is required
```

```{r Q15}
# KPSS Test for Stationarity for 2nd difference order
kpss.test(diff(train_ts_trans, lag = 24), null = c("Level", "Trend"), lshort = TRUE)
```

The p-value is still 0.1.
Since this value is not less than .05, we fail to reject the null hypothesis of the KPSS test.
This means we can assume that the time series data is stationary.
A Box-Cox transformation and 1st order differencing is still a good idea for this time series training data.

```{r Q27}


```

```{r Q27}


```

```{r Q27}


```

```{r Q27}
# Calculate the EACF
eacf(train_ts)
```

```{r Q27}
# Using Auto.arima() first to find best optimal
fit<- auto.arima(train_ts, d = 1, D = 1, lambda = 'auto', seasonal = TRUE, trace = TRUE)
```

```{r Q27}
summary(fit)
```

```{r Q27}
fit_forecast <- forecast(fit, h = length(test_ts))
# forecast::autoplot(fit_forecast)
# plot(fit_forecast)
plot(fit_forecast, xlim = c(140, 190))
# length(fit_forecast)
# , xlim = c(140, 190)
# , xlim = c(3400, 4500)
```

```{r Q27}
fit_2<- auto.arima(train_ts, d = 1, lambda = 'auto', seasonal = TRUE, trace = TRUE)
```

```{r Q27}
summary(fit_2)
```

```{r Q27}
fit_forecast <- forecast(fit_2, h = length(test_ts))
# forecast::autoplot(fit_forecast)
# plot(fit_forecast)
plot(fit_forecast, xlim = c(140, 190))
# length(fit_forecast)
# , xlim = c(140, 190)
# , xlim = c(3400, 4500)
```

```{r Q27}
fit_3<- auto.arima(train_ts, lambda = 'auto', seasonal = TRUE, trace = TRUE)
```

```{r Q27}
summary(fit_3)
```

```{r Q27}
fit_forecast <- forecast(fit_3, h = length(test_ts))
# forecast::autoplot(fit_forecast)
# plot(fit_forecast)
plot(fit_forecast, xlim = c(140, 190))
# length(fit_forecast)
# , xlim = c(140, 190)
# , xlim = c(3400, 4500)
```

```{r Q27}
fit_4<- auto.arima(train_ts, lambda = 'auto', trace = TRUE)
```

```{r Q27}
summary(fit_4)
```

```{r Q27}
fit_forecast <- forecast(fit_4, h = length(test_ts))
# forecast::autoplot(fit_forecast)
# plot(fit_forecast)
plot(fit_forecast, xlim = c(140, 190))
# length(fit_forecast)
```

```{r Q27}
plot(resid(fit_2),main='Residuals of fit_2 Model')
plot(fit_2$residuals,main='Residuals of fit_2 Model')
tsdisplay(residuals(fit_2))
```

```{r Q27}
# residual plot for ARIMA(0,1,5)(2,1,0)[24]
checkresiduals(fit_2, lag = 24)
```

```{r Q27}
# ARIMA(3,0,5)(1,0,1)[24]
model_test <- Arima(train_ts, order = c(3, 0, 5), seasonal = list(order = c(1, 0, 1), period=24), lambda = 'auto')
```

```{r Q27}


```

```{r Q27}


```

```{r Q27}


```

```{r Q22}
# Function to calculate MAE and RMSE
calculate_errors <- function(actual, forecast) {
  mae <- mean(abs(actual - forecast))
  rmse <- sqrt(mean((actual - forecast)^2))
  return(c(mae = mae, rmse = rmse))
}
```

```{r Q27}
# Custom function to calculate AICc for ARIMA models
AICc <- function(model) {
  k <- length(coef(model))
  n <- length(model$residuals)
  AIC(model) + 2 * k * (k + 1) / (n - k - 1)
}
```

```{r Q27}
find_best_models_2 <- function(forecast_period) {
  # Initialize variables
  model_data <- data.frame(Model = character(),
                           AICc = numeric(),
                           BIC = numeric(),
                           ME = numeric(),
                           RMSE = numeric(),
                           MAE = numeric(),
                           MPE = numeric(),
                           MAPE = numeric(),
                           MASE = numeric(),
                           MSE = numeric(),
                           stringsAsFactors = FALSE)
  
  # Loop over possible ARIMA parameters
  for (p in 0:3) {
    for (d in 0:1) {
      for (q in 0:3) {
        for (sp in 0:3) {
          for (sd in 0:1) {
            for (sq in 0:3) {
              # Fit the ARIMA model with error handling
              tryCatch({
              model <- Arima(train_ts, order = c(p, d, q), seasonal = list(order = c(sp, sd, sq), period=24), lambda = 'auto', method = "CSS")
              
              # Calculate AICc and BIC
              aicc <- AICc(model)
              bic <- BIC(model)
              
              forecast <- forecast(model, h = forecast_period)
              accuracy_values <- forecast::accuracy(forecast, test_df$traffic_volume[(length(test_df$traffic_volume) - forecast_period + 1):length(test_df$traffic_volume)])
              # Mean Error
              me <- round(accuracy_values[2], 4)
              # Root Mean Square Error
              rmse <- round(accuracy_values[4], 4)
              # Mean Absolute Error
              mae <- round(accuracy_values[6], 4)
              # Mean Percentage Error
              mpe <- round(accuracy_values[8], 4)
              # Mean Absolute Percentage Error (MAPE)
              mape <- round(accuracy_values[10], 4)
              # Mean Absolute Scaled Error
              mase <- round(accuracy_values[12], 4)
              # Mean Squared Error (MSE)
              mse <- mean((forecast$mean - test_df$traffic_volume[(length(test_df$traffic_volume) - forecast_period + 1):length(test_df$traffic_volume)])^2)
              
              # Store the model and its metrics in the dataframe
              model_data <- rbind(model_data, data.frame(Model = paste0("ARIMA(", p, ",", d, ",", q, ")(", sp, ",", sd, ",", sq, ")"),
                                                         AICc = aicc,
                                                         BIC = bic,
                                                         ME = me,
                                                         RMSE = rmse,
                                                         MAE = mae,
                                                         MPE = mpe,
                                                         MAPE = mape,
                                                         MASE = mase,
                                                         MSE = mse,
                                                         stringsAsFactors = FALSE))
              print(paste0("ARIMA(", p, ",", d, ",", q, ")(", sp, ",", sd, ",", sq, ")"))
              }, error = function(e) {
                 # Skip problematic model fits and continue
                  message("Error fitting model: ", e$message)
              }, #if a warning occurs, tell me the warning
                 warning=function(w) {
                      message('A Warning Occurred: ', w$message)
        })
            }
          }
        }
      }
    }
  }

  # Sort the dataframe by AICc in ascending order
  model_data <- model_data[order(model_data$AICc), ]
  
  # Return the sorted dataframe
  return(model_data)
}
```

```{r Q27}
# Time difference of 10.93927 hours
# 903/1024 combinations were fitted
start <- Sys.time()
result_month <- find_best_models_2(length(test_ts))
print( Sys.time() - start )
```

```{r Q1}
result_month <- read.csv("result_month.csv")
```

```{r Q27}
# output_file <- "C:/Users/vamsh/Documents/Uni/UChicago/Spring 2023/MSCA 31006_IP03 - Time Series Analysis and Forecasting/Project/result_month.csv"
# write.csv(result_month, file = output_file, row.names = FALSE)
# cat("Table saved to CSV:", output_file, "\n")
```

```{r Q27}
# Time difference of 11.19717 hours
# 903/1024 combinations were fitted
# Main errors were (added method = "CSS" in Arima() function as a potential fix but needs to be confirmed):
#   Error fitting model: initial value in 'vmmin' is not finite
#   Error fitting model: non-finite finite-difference value [1]
start <- Sys.time()
result_week <- find_best_models_2(24*7)
print( Sys.time() - start )
```

```{r Q1}
result_week <- read.csv("result_week.csv")
```

```{r Q27}
# output_file <- "C:/Users/vamsh/Documents/Uni/UChicago/Spring 2023/MSCA 31006_IP03 - Time Series Analysis and Forecasting/Project/result_week.csv"
# write.csv(result_week, file = output_file, row.names = FALSE)
# cat("Table saved to CSV:", output_file, "\n")
```

```{r Q27}
# Time difference of 10.86862 hours
# 903/1024 combinations were fitted
start <- Sys.time()
result_24hr <- find_best_models_2(24)
print( Sys.time() - start )
```

```{r Q1}
result_24hr <- read.csv("result_24hr.csv")
```

```{r Q27}
# output_file <- "C:/Users/vamsh/Documents/Uni/UChicago/Spring 2023/MSCA 31006_IP03 - Time Series Analysis and Forecasting/Project/result_24hr.csv"
# write.csv(result_24hr, file = output_file, row.names = FALSE)
# cat("Table saved to CSV:", output_file, "\n")
```

```{r Q27}
# 1 month forecast
# ARIMA(2,0,3)(0,1,2) #1
# ARIMA(2,0,3)(1,1,1) #2
# ARIMA(3,0,3)(0,1,2) #2
# ARIMA(2,0,3)(0,1,3) #2
```

```{r Q27}
model_test_month <- Arima(train_ts, order = c(2,0,3), seasonal = list(order = c(0,1,2), period=24), lambda = 'auto')
```

```{r Q27}
summary(model_test_month)
```

```{r Q27}
fit_forecast_month <- forecast(model_test_month, h = length(test_ts))
# forecast::autoplot(fit_forecast)
# plot(fit_forecast)
# plot(fit_forecast_month, xlim = c(140, 190))
# title(sub = "1 Month forecast", line = -14.5, cex.sub = 1)
# length(fit_forecast)
# xlim = c(140, 190)
# ylim = c(0, 8000)
```

```{r Q27}
data_forecast_month <- data.frame(Time = test_df$date_time,
                   Actual = test_df$traffic_volume,
                   Forecasted = fit_forecast_month)
```

```{r Q27}
# Plot the forecasted vs. actual values
ggplot(data_forecast_month, aes(Time)) +
  geom_ribbon(aes(ymin = Forecasted.Lo.95, ymax = Forecasted.Hi.95),
              fill = "#BFD4E9", alpha = 0.5) +
  geom_ribbon(aes(ymin = Forecasted.Lo.80, ymax = Forecasted.Hi.80),
              fill = "#9FC5E8", alpha = 0.5) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Forecasted.Point.Forecast, color = "Forecasted")) +
  labs(x = "Time", y = "Traffic Volume") +
  scale_color_manual(values = c(Actual = "red", Forecasted = "blue")) +
  theme_minimal() + ggtitle("1 Month Forecast vs. Actual Values for ARIMA(2,0,3)(0,1,2)[24]")
```

```{r Q27}
# Accuracy for 1 month
forecast::accuracy(fit_forecast_month, test_df$traffic_volume[(length(test_df$traffic_volume) - length(test_ts) + 1):length(test_df$traffic_volume)]) %>% round(4)
```

```{r Q27}
# plot(resid(model_test_month),main='Residuals of model_test Model')
# plot(model_test_month$residuals,main='Residuals of fit_2 Model')
# tsdisplay(residuals(model_test_month))
```

```{r Q27}
# residual plot for ARIMA(2,0,3)(0,1,2)[24]
checkresiduals(model_test_month, lag = 24)
```

```{r Q27}
# 1 week forecast
# ARIMA(1,0,1)(3,1,0) #1
# ARIMA(1,0,2)(3,1,0) #2
# ARIMA(2,0,3)(3,1,0) #2
```

```{r Q27}
model_test_week <- Arima(train_ts, order = c(1,0,1), seasonal = list(order = c(3,1,0), period=24), lambda = 'auto')
```

```{r Q27}
summary(model_test_week)
```

```{r Q27}
# For unknown reason 24*7 records from the test data doesn't contain a week's worth of observations, therefore forecast period is set to longer than 24*7 to cover the full week
fit_forecast_week <- forecast(model_test_week, h=24*7 + 83)
# forecast::autoplot(fit_forecast)
# plot(fit_forecast)
# plot(fit_forecast_week, xlim = c(140, 157))
# title(sub = "1 Week forecast", line = -14.5, cex.sub = 1)
# length(fit_forecast)
# xlim = c(140, 190)
# ylim = c(0, 8000)
```

```{r Q27}
data_forecast_week <- data.frame(Time = test_df$date_time[0:251],
                   Actual = test_df$traffic_volume[0:251],
                   Forecasted = fit_forecast_week)
```

```{r Q27}
# Plot the forecasted vs. actual values
ggplot(data_forecast_week, aes(Time)) +
  geom_ribbon(aes(ymin = Forecasted.Lo.95, ymax = Forecasted.Hi.95),
              fill = "#BFD4E9", alpha = 0.5) +
  geom_ribbon(aes(ymin = Forecasted.Lo.80, ymax = Forecasted.Hi.80),
              fill = "#9FC5E8", alpha = 0.5) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Forecasted.Point.Forecast, color = "Forecasted")) +
  labs(x = "Time", y = "Traffic Volume") +
  scale_color_manual(values = c(Actual = "red", Forecasted = "blue")) +
  theme_minimal() + ggtitle("1 Week Forecast vs. Actual Values for ARIMA(1,0,1)(3,1,0)[24]")
```

```{r Q27}
# Accuracy for 1 week
forecast::accuracy(fit_forecast_week, test_df$traffic_volume[(length(test_df$traffic_volume) - 24*7 + 1):length(test_df$traffic_volume)]) %>% round(4)
```

```{r Q27}
# plot(resid(model_test_week),main='Residuals of model_test Model')
# plot(model_test_week$residuals,main='Residuals of fit_2 Model')
# tsdisplay(residuals(model_test_week))
```

```{r Q27}
# residual plot for ARIMA(1,0,1)(3,1,0)[24]
checkresiduals(model_test_week, lag = 24)
```

```{r Q27}
# 24 hour forecast
# ARIMA(2,0,3)(3,1,0) #1
# ARIMA(2,0,3)(0,0,3) #2
# ARIMA(2,0,1)(0,0,2) #2
```

```{r Q27}
model_test_24hour <- Arima(train_ts, order = c(2,0,3), seasonal = list(order = c(3,1,0), period=24), lambda = 'auto')
```

```{r Q27}
summary(model_test_24hour)
```

```{r Q27}
# For unknown reason 24 records from the test data doesn't contain 24 hours worth of observations, therefore forecast period is set to longer than 24 to cover the full 24 hours
fit_forecast_24hour <- forecast(model_test_24hour, h=28)
# forecast::autoplot(fit_forecast)
# plot(fit_forecast)
# plot(fit_forecast_24hour, xlim = c(140, 150))
# title(sub = "24 hour forecast", line = -14.5, cex.sub = 1)
# length(fit_forecast)
# xlim = c(140, 190)
# ylim = c(0, 8000)
```

```{r Q27}
data_forecast_24hour <- data.frame(Time = test_df$date_time[0:28],
                   Actual = test_df$traffic_volume[0:28],
                   Forecasted = fit_forecast_24hour)
```

```{r Q27}
# Plot the forecasted vs. actual values
ggplot(data_forecast_24hour, aes(Time)) +
  geom_ribbon(aes(ymin = Forecasted.Lo.95, ymax = Forecasted.Hi.95),
              fill = "#BFD4E9", alpha = 0.5) +
  geom_ribbon(aes(ymin = Forecasted.Lo.80, ymax = Forecasted.Hi.80),
              fill = "#9FC5E8", alpha = 0.5) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Forecasted.Point.Forecast, color = "Forecasted")) +
  labs(x = "Time", y = "Traffic Volume") +
  scale_color_manual(values = c(Actual = "red", Forecasted = "blue")) +
  theme_minimal() + ggtitle("24 Hour Forecast vs. Actual Values for ARIMA(2,0,3)(3,1,0)[24]")
```

```{r Q27}
# Accuracy for 24 hours
forecast::accuracy(fit_forecast_24hour, test_df$traffic_volume[(length(test_df$traffic_volume) - 24 + 1):length(test_df$traffic_volume)]) %>% round(4)
```

```{r Q27}
# plot(resid(model_test_24hour),main='Residuals of model_test Model')
# plot(model_test_24hour$residuals,main='Residuals of fit_2 Model')
# tsdisplay(residuals(model_test_24hour))
```

```{r Q27}
# residual plot for ARIMA(2,0,3)(3,1,0)[24]
checkresiduals(model_test_24hour, lag = 24)
```

```{r Q27}


```

```{r Q27}


```

```{r Q27}


```
